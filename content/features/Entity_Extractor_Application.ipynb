{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "\n",
    "from collections import defaultdict\n",
    "import srsly\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from spacy.errors import Errors\n",
    "from spacy.compat import basestring_\n",
    "from spacy.util import ensure_path\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "class EntityMatcher(object):\n",
    "    name = \"entity_matcher\"\n",
    "\n",
    "    def __init__(self, nlp,**cfg):\n",
    "        self.nlp = nlp\n",
    "        self.overwrite = cfg.get(\"overwrite_ents\", False)\n",
    "        self.token_patterns = defaultdict(list)\n",
    "        self.phrase_patterns = defaultdict(list)\n",
    "        self.matcher = Matcher(nlp.vocab)\n",
    "        self.phrase_matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "        patterns = cfg.get(\"patterns\")\n",
    "        if patterns is not None:\n",
    "            self.add_patterns(patterns)\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\"The number of all patterns added to the entity ruler.\"\"\"\n",
    "        n_token_patterns = sum(len(p) for p in self.token_patterns.values())\n",
    "        n_phrase_patterns = sum(len(p) for p in self.phrase_patterns.values())\n",
    "        return n_token_patterns + n_phrase_patterns\n",
    "    \n",
    "    def __contains__(self, label):\n",
    "        \"\"\"Whether a label is present in the patterns.\"\"\"\n",
    "        return label in self.token_patterns or label in self.phrase_patterns\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        \"\"\"Find matches in document and add them as entities.\n",
    "\n",
    "        doc (Doc): The Doc object in the pipeline.\n",
    "        RETURNS (Doc): The Doc with added entities, if available.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#call\n",
    "        \"\"\"\n",
    "        \n",
    "        matches = list(self.matcher(doc)) + list(self.phrase_matcher(doc))\n",
    "        \n",
    "        matches = set(\n",
    "            [(m_id, start, end) for m_id, start, end in matches if start != end]\n",
    "        )\n",
    "        get_sort_key = lambda m: (m[2] - m[1], m[1])\n",
    "        matches = sorted(matches, key=get_sort_key, reverse=False)\n",
    "        \n",
    "        \n",
    "        entities = list(doc.ents)\n",
    "        new_entities = []\n",
    "        seen_tokens = set()\n",
    "        for match_id, start, end in matches:\n",
    "            \n",
    "            if any(t.ent_type for t in doc[start:end]) and not self.overwrite:\n",
    "                continue\n",
    "            \n",
    "            if start not in seen_tokens and end - 1 not in seen_tokens:\n",
    "\n",
    "                new_entities.append(Span(doc, start, end, label=match_id))\n",
    "\n",
    "                entities = [e for e in entities if not (e.start < end and e.end > start)]\n",
    "                seen_tokens.update(range(start, end))\n",
    "                \n",
    "        doc.ents = entities + new_entities\n",
    "\n",
    "        return doc\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        \"\"\"All labels present in the match patterns.\n",
    "\n",
    "        RETURNS (set): The string labels.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#labels\n",
    "        \"\"\"\n",
    "        all_labels = set(self.token_patterns.keys())\n",
    "        all_labels.update(self.phrase_patterns.keys())\n",
    "        return tuple(all_labels)\n",
    "\n",
    "    @property\n",
    "    def patterns(self):\n",
    "        \"\"\"Get all patterns that were added to the entity ruler.\n",
    "\n",
    "        RETURNS (list): The original patterns, one dictionary per pattern.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#patterns\n",
    "        \"\"\"\n",
    "        all_patterns = []\n",
    "        for label, patterns in self.token_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                all_patterns.append({\"label\": label, \"pattern\": pattern})\n",
    "        for label, patterns in self.phrase_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                all_patterns.append({\"label\": label, \"pattern\": pattern.text})\n",
    "        return all_patterns\n",
    "\n",
    "    def add_patterns(self, patterns):\n",
    "        \"\"\"Add patterns to the entitiy ruler. A pattern can either be a token\n",
    "        pattern (list of dicts) or a phrase pattern (string). For example:\n",
    "        {'label': 'ORG', 'pattern': 'Apple'}\n",
    "        {'label': 'GPE', 'pattern': [{'lower': 'san'}, {'lower': 'francisco'}]}\n",
    "\n",
    "        patterns (list): The patterns to add.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#add_patterns\n",
    "        \"\"\"\n",
    "        for entry in patterns:\n",
    "            label = entry[\"label\"]\n",
    "            pattern = entry[\"pattern\"]\n",
    "            on_match = entry['on_match']\n",
    "            \n",
    "            if on_match == 'None':\n",
    "                on_matcher = None\n",
    "            else:\n",
    "\n",
    "                print(label)\n",
    "                def on_matcher(matcher, doc, id, matches):\n",
    "                    match_id, start, end = matches[-1]\n",
    "                    print('This is the on match[0]:')\n",
    "                    print(on_match[0])\n",
    "                    for callback in on_match:\n",
    "                        print('This is the callback:')\n",
    "                        print(callback)\n",
    "                        if 'TRUNCR' in callback.keys():\n",
    "                            end = end - callback['TRUNCR']\n",
    "                            matches[id] = (match_id, start, end)\n",
    "\n",
    "                    \n",
    "                        if 'TRUNCL' in callback.keys():\n",
    "                            start = start + callback['TRUNCL']\n",
    "                            matches[id] = (match_id, start, end)\n",
    "                            \n",
    "#                    matches.append(('sub-CLUE',start - callback['TRUNCL'],start))\n",
    "                    print(matches)\n",
    "                        \n",
    "\n",
    "            if isinstance(pattern, basestring_):\n",
    "                self.phrase_patterns[label].append(self.nlp(pattern))\n",
    "            elif isinstance(pattern, list):\n",
    "                self.token_patterns[label].append((on_matcher,pattern))\n",
    "\n",
    "            else:\n",
    "                raise ValueError(Errors.E097.format(pattern=pattern))\n",
    "                \n",
    "\n",
    "\n",
    "        for label, match in self.token_patterns.items():\n",
    "            for on_matcher,pattern in match:\n",
    "                self.matcher.add(label, on_matcher, pattern)\n",
    "        for label, patterns in self.phrase_patterns.items():\n",
    "            self.phrase_matcher.add(label, None, *patterns)\n",
    "\n",
    "    def from_bytes(self, patterns_bytes, **kwargs):\n",
    "        \"\"\"Load the entity ruler from a bytestring.\n",
    "\n",
    "        patterns_bytes (bytes): The bytestring to load.\n",
    "        **kwargs: Other config paramters, mostly for consistency.\n",
    "        RETURNS (EntityRuler): The loaded entity ruler.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#from_bytes\n",
    "        \"\"\"\n",
    "        patterns = srsly.msgpack_loads(patterns_bytes)\n",
    "        self.add_patterns(patterns)\n",
    "        return self\n",
    "\n",
    "    def to_bytes(self, **kwargs):\n",
    "        \"\"\"Serialize the entity ruler patterns to a bytestring.\n",
    "\n",
    "        RETURNS (bytes): The serialized patterns.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#to_bytes\n",
    "        \"\"\"\n",
    "        return srsly.msgpack_dumps(self.patterns)\n",
    "\n",
    "    def from_disk(self, path, **kwargs):\n",
    "        \"\"\"Load the entity ruler from a file. Expects a file containing\n",
    "        newline-delimited JSON (JSONL) with one entry per line.\n",
    "\n",
    "        path (unicode / Path): The JSONL file to load.\n",
    "        **kwargs: Other config paramters, mostly for consistency.\n",
    "        RETURNS (EntityRuler): The loaded entity ruler.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#from_disk\n",
    "        \"\"\"\n",
    "        path = ensure_path(path)\n",
    "        path = path.with_suffix(\".jsonl\")\n",
    "        patterns = srsly.read_jsonl(path)\n",
    "        self.add_patterns(patterns)\n",
    "        return self\n",
    "\n",
    "    def to_disk(self, path, **kwargs):\n",
    "        \"\"\"Save the entity ruler patterns to a directory. The patterns will be\n",
    "        saved as newline-delimited JSON (JSONL).\n",
    "\n",
    "        path (unicode / Path): The JSONL file to load.\n",
    "        **kwargs: Other config paramters, mostly for consistency.\n",
    "        RETURNS (EntityRuler): The loaded entity ruler.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#to_disk\n",
    "        \"\"\"\n",
    "        path = ensure_path(path)\n",
    "        path = path.with_suffix(\".jsonl\")\n",
    "        srsly.write_jsonl(path, self.patterns)\n",
    "\n",
    "        \n",
    "def render_doc(doc, entity = False):\n",
    "    '''This function render the text of the documents with the entity signed'''\n",
    "    \n",
    "    out = displacy.parse_ents(doc)\n",
    "    print(out)\n",
    "    adder = 0\n",
    "    \n",
    "    for i,ent in enumerate(out['ents']):\n",
    "                \n",
    "        #do not add the first entity match\n",
    "        out['ents'][i]['start'] += i*adder\n",
    "        out['ents'][i]['end'] += i*adder\n",
    "        \n",
    "        if entity == False:\n",
    "            adder = 4\n",
    "            if ent['label'] == 'sub-CLUE':\n",
    "                out['text'] = out['text'][:ent['start']] + '_*' + out['text'][ent['start']:ent['end']] + '*_' + out['text'][ent['end']:]\n",
    "            else:\n",
    "                out['text'] = out['text'][:ent['start']] + '**' + out['text'][ent['start']:ent['end']] + '**' + out['text'][ent['end']:]\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            adder = len(ent['label']) + 6\n",
    "            if ent['label'] == 'sub-CLUE':\n",
    "                out['text'] = out['text'][:ent['start']] + '_*' + out['text'][ent['start']:ent['end']] + '*_{' + ent['label'] + '}' + out['text'][ent['end']:]\n",
    "            else:\n",
    "                out['text'] = out['text'][:ent['start']] + '**' + out['text'][ent['start']:ent['end']] + '**{' + ent['label'] + '}' + out['text'][ent['end']:]\n",
    "            \n",
    "        \n",
    "    return out['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('../15. Cluster SS-ESCO/data/input/ulisseDB.xlsx')\n",
    "\n",
    "for sheet in xls.sheet_names:\n",
    "    globals()[sheet] = xls.parse(sheet_name = sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "nlp = spacy.load(\"it_core_news_sm\")\n",
    "\n",
    "\n",
    "entity_matcher = EntityMatcher(nlp).from_disk(\"gestione.jsonl\")\n",
    "nlp.add_pipe(entity_matcher)\n",
    "\n",
    "\n",
    "#TEXTS = Abstracts.abstract.tolist()\n",
    "\n",
    "for text in TEXTS:\n",
    "    doc = nlp(text)\n",
    "    print([ent.label_ for ent in doc.ents if (ent.label_ == 'PROBLEM SOLVING')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Â© The Author(s) 2016. The aim of this study was to evaluate the impact of a social contact and education intervention to improve attitudes to mental illness in first-year social work students. This was a 3-month cluster randomized controlled trial with two parallel arms: intervention (87) and control group (79). The intervention was a workshop led by an OBERTAMENT activist (a person with a mental illness trained in communication skills and empowerment by a social worker). We assessed intended future behavior toward people with mental illness, personal and perceived stigma, and mental healthâ€“related attitudes (self-reported questionnaire). The intervention improved social work studentsâ€™ attitudes (d ÍŒ 0.50, p <.05) and reduced personal stigma toward people with mental illness (d = 0.35, p = 04) as well as improving their future intended behavior 2 weeks after the intervention (d = 0.51, p =.01). The intervention impact on authoritarian attitudes toward people with schizophrenia was maintained after 3 months (d = 0.94, p =.01). Long-term impact needs to be improved."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_env",
   "language": "python",
   "name": "spacy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
